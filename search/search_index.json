{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Firecracker Shim","text":"<p>A containerd runtime (shim v2) that runs Kubernetes pod sandboxes inside Firecracker microVMs.</p> <p>Firecracker isolation, Kubernetes-native, without Kata's complexity.</p>"},{"location":"#what-this-is","title":"What This Is","text":"<p>This project provides a containerd shim that creates Firecracker microVMs for pod sandboxes. Kubernetes uses it via RuntimeClass + containerd\u2014no changes to kubelet or CRI required.</p> <pre><code>Kubernetes \u2192 kubelet \u2192 containerd (CRI) \u2192 containerd-shim-fc-v2 \u2192 Firecracker VM\n                                                                        \u2193\n                                                                   fc-agent \u2192 runc \u2192 container\n</code></pre>"},{"location":"#security-model","title":"Security Model","text":"<ul> <li>1 VM per pod sandbox (matches Kata semantics)</li> <li>Each pod runs in a dedicated microVM with its own kernel</li> <li>Containers within the pod share the VM (standard pod networking)</li> <li>VM-level isolation protects host from untrusted workloads</li> </ul>"},{"location":"#why-another-runtime","title":"Why Another Runtime?","text":"<p>If you want stronger isolation than standard Linux containers (cgroups/namespaces), you typically look at two options: Kata Containers or firecracker-containerd. Both are excellent, but we found them operationally complex for our needs.</p>"},{"location":"#vs-firecracker-containerd","title":"vs. firecracker-containerd","text":"<p>AWS's <code>firecracker-containerd</code> pioneered this space, but it uses a daemon-based architecture that sits between containerd and the VMs. This adds complexity to debugging, image handling (often requiring custom snapshotters), and networking setup.</p> <p>firecracker-shim takes a different approach:</p> <ul> <li>Shim v2 Architecture: No middleman daemon. containerd talks directly to our shim, which talks directly to Firecracker.</li> <li>Standard OCI Images: No complex device mapper setup. We convert standard Docker images to ext4 block devices on the fly.</li> <li>Standard Networking: We use standard CNI plugins via a bridge, so your existing Calico/Flannel/AWS-VPC-CNI just works.</li> </ul> <p>See full comparison: Daemon vs Shim Architecture</p>"},{"location":"#vs-kata-containers","title":"vs. Kata Containers","text":"<p>Kata is a powerful, multi-hypervisor runtime (QEMU, Cloud Hypervisor, Firecracker, etc.). That flexibility comes with abstraction overhead (~160MB+ memory per pod vs our ~64MB) and a larger architectural footprint.</p> <p>We built firecracker-shim to be:</p> <ol> <li>Single-purpose: Optimized solely for Firecracker.</li> <li>Lean: Minimal agent (~2MB), minimal kernel, minimal overhead.</li> <li>Fast: Sub-50ms warm starts via VM pooling.</li> </ol>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Kubernetes Node                                                          \u2502\n\u2502                                                                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502   kubelet   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502               containerd                      \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502                   \u2502                           \u2502    \u2502\n\u2502                      \u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502    \u2502\n\u2502                      \u2502         \u25bc                   \u25bc                 \u2502    \u2502\n\u2502                      \u2502    CRI Plugin          Shim Manager           \u2502    \u2502\n\u2502                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                \u2502                   \u2502                      \u2502\n\u2502                                \u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502                                \u2502     \u2502  containerd-shim-fc-v2    \u2502        \u2502\n\u2502                                \u2502     \u2502  (one per pod sandbox)    \u2502        \u2502\n\u2502                                \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502                                \u2502                   \u2502                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  VM Pool                    \u2502                   \u2502                   \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502  \u2502\n\u2502  \u2502  \u2502 warm  \u2502 \u2502 warm  \u2502 \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502      Firecracker VMM      \u2502     \u2502  \u2502\n\u2502  \u2502  \u2502  VM   \u2502 \u2502  VM   \u2502              \u2502            \u2502               \u2502     \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502     \u2502             \u2502       \u2502\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                      \u2502     \u2502  microVM    \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502             \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u2502fc-agen\u2502\u25c0\u2500\u253c\u2500vsock\u2500\u2524        \u2502\n\u2502                                      \u2502     \u2502  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502      \u2502      \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u2502 runc  \u2502  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u2502  \u2502    \u2502  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u2502 \u250c\u25bc\u2500\u2500\u2510 \u2502  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u2502 \u2502app\u2502 \u2502  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u2502 \u2514\u2500\u2500\u2500\u2518 \u2502  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502       \u2502        \u2502\n\u2502                                      \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502        \u2502\n\u2502                                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#features","title":"Features","text":"Feature Description VM Pooling Pre-warmed VMs for fast acquisition (&lt;50ms) Minimal Footprint 64-128MB memory per VM vsock Communication Efficient host\u2194guest via virtio-vsock CNI Networking Standard CNI plugin support Jailer Support Optional privilege isolation Prometheus Metrics Pool stats, latencies, errors Debug CLI <code>fcctl</code> for inspection and troubleshooting"},{"location":"#non-goals","title":"Non-Goals","text":"<ul> <li>Not a CRI implementation: We're a containerd shim, not a replacement for containerd/CRI</li> <li>Not cross-platform: Linux only, requires KVM</li> <li>No nested virtualization: Requires bare-metal or VM with nested virt enabled</li> <li>Snapshots are best-effort: Host-kernel sensitive, not guaranteed portable</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<pre><code># Check KVM support\nls -la /dev/kvm\n\n# Check vsock support\nls -la /dev/vhost-vsock\n\n# Required: containerd 1.7+\ncontainerd --version\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code># Clone\ngit clone https://github.com/PipeOpsHQ/firecracker-shim\ncd firecracker-shim\n\n# Install dependencies (fsify, skopeo, umoci)\nmake deps\n\n# Build binaries\nmake build\n\n# Build or download kernel (takes ~10 min to build)\nmake kernel\n\n# Create base rootfs\nmake rootfs\n\n# Install\nsudo make install\n\n# Restart containerd\nsudo systemctl restart containerd\n</code></pre>"},{"location":"#verify-installation","title":"Verify Installation","text":"<pre><code># Check health\nsudo fcctl health\n\n# List sandboxes (should be empty initially)\nsudo fcctl list\n</code></pre>"},{"location":"#usage-with-kubernetes","title":"Usage with Kubernetes","text":"<ol> <li>Apply RuntimeClass:</li> </ol> <pre><code># runtime-class.yaml\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: firecracker\nhandler: firecracker\noverhead:\n  podFixed:\n    memory: \"64Mi\"\n    cpu: \"100m\"\nscheduling:\n  nodeSelector:\n    fc-cri.io/enabled: \"true\" # Label your fc-cri nodes\n</code></pre> <pre><code>kubectl apply -f runtime-class.yaml\n</code></pre> <ol> <li>Deploy a pod:</li> </ol> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: isolated-workload\nspec:\n  runtimeClassName: firecracker\n  containers:\n    - name: app\n      image: nginx:alpine\n      resources:\n        requests:\n          memory: \"64Mi\"\n          cpu: \"100m\"\n</code></pre> <ol> <li>Verify it's running in a VM:</li> </ol> <pre><code>kubectl get pod isolated-workload -o wide\nsudo fcctl list\nsudo fcctl inspect &lt;sandbox-id&gt;\n</code></pre>"},{"location":"#configuration","title":"Configuration","text":""},{"location":"#runtime-configuration","title":"Runtime Configuration","text":"<pre><code># /etc/fc-cri/config.toml\n\n[runtime]\nruntime_dir = \"/run/fc-cri\"\nfirecracker_binary = \"/usr/bin/firecracker\"\nshutdown_timeout = \"30s\"\n\n[vm]\nkernel_path = \"/var/lib/fc-cri/vmlinux\"\nkernel_args = \"console=ttyS0 reboot=k panic=1 pci=off quiet\"\ndefault_vcpu_count = 1\ndefault_memory_mb = 128\nmin_memory_mb = 64\nmax_memory_mb = 8192\n\n[pool]\nenabled = true\nmax_size = 10\nmin_size = 3\nmax_idle_time = \"5m\"\nwarm_concurrency = 2\n\n[network]\nnetwork_mode = \"cni\"\ncni_plugin_dir = \"/opt/cni/bin\"\ncni_conf_dir = \"/etc/cni/net.d\"\n\n[agent]\nvsock_port = 1024\nconnect_timeout = \"30s\"\n\n[metrics]\nenabled = true\naddress = \":9090\"\npath = \"/metrics\"\n\n[log]\nlevel = \"info\"  # debug, info, warn, error\nformat = \"text\" # text, json\n</code></pre>"},{"location":"#containerd-configuration","title":"containerd Configuration","text":"<pre><code># /etc/containerd/config.d/firecracker.toml\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.firecracker]\n  runtime_type = \"io.containerd.firecracker.v2\"\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.firecracker.options]\n  ConfigPath = \"/etc/fc-cri/config.toml\"\n</code></pre>"},{"location":"#components","title":"Components","text":""},{"location":"#containerd-shim-fc-v2","title":"containerd-shim-fc-v2","text":"<p>The main shim binary launched by containerd for each pod sandbox.</p> <pre><code>/usr/local/bin/containerd-shim-fc-v2\n</code></pre> <p>Responsibilities:</p> <ul> <li>Implements containerd shim v2 protocol</li> <li>Manages Firecracker VM lifecycle</li> <li>Communicates with fc-agent via vsock</li> <li>Handles container create/start/stop/delete</li> </ul>"},{"location":"#fc-agent","title":"fc-agent","text":"<p>Minimal agent running inside the microVM (~2-3MB static binary).</p> <pre><code>/usr/local/bin/fc-agent  (inside VM at /usr/local/bin/fc-agent)\n</code></pre> <p>Responsibilities:</p> <ul> <li>Listens on vsock port 1024</li> <li>Executes container operations via runc</li> <li>Streams stdout/stderr</li> <li>Reports container stats</li> </ul>"},{"location":"#fcctl","title":"fcctl","text":"<p>Debug and inspection CLI.</p> <pre><code># List all sandboxes\nfcctl list\n\n# Detailed inspection\nfcctl inspect fc-1234567890\n\n# Pool status\nfcctl pool status\n\n# View metrics\nfcctl metrics\n\n# Stream logs\nfcctl logs fc-1234567890 -f\n\n# Execute command in VM\nfcctl exec fc-1234567890 cat /etc/os-release\n\n# Health check\nfcctl health\n\n# Clean up orphaned resources\nfcctl cleanup --dry-run\n</code></pre>"},{"location":"#performance","title":"Performance","text":"<p>Test Environment: 4 vCPU, 8GB RAM, Intel Xeon, ext4, containerd 1.7</p> Metric Value Notes Cold start (create \u2192 running) ~150ms Excludes image pull Warm start (from pool) &lt;50ms Pre-warmed VM Memory per VM 64-128MB Depends on workload Agent binary size ~2.5MB Static binary Kernel size ~5MB Minimal config <p>Pool Hit Rates (after warm-up):</p> <ul> <li>Steady workload: 85-95% hit rate</li> <li>Bursty workload: 60-80% hit rate</li> </ul>"},{"location":"#networking","title":"Networking","text":""},{"location":"#cni-integration","title":"CNI Integration","text":"<p>We support standard CNI plugins. The default configuration uses bridge networking:</p> <pre><code>{\n  \"cniVersion\": \"1.0.0\",\n  \"name\": \"fc-net\",\n  \"plugins\": [\n    {\n      \"type\": \"bridge\",\n      \"bridge\": \"fc-br0\",\n      \"isGateway\": true,\n      \"ipMasq\": true,\n      \"ipam\": {\n        \"type\": \"host-local\",\n        \"subnet\": \"10.88.0.0/16\"\n      }\n    },\n    {\n      \"type\": \"portmap\",\n      \"capabilities\": { \"portMappings\": true }\n    }\n  ]\n}\n</code></pre>"},{"location":"#network-flow","title":"Network Flow","text":"<ol> <li>CNI creates tap device and assigns IP</li> <li>Firecracker attaches tap to virtio-net</li> <li>Guest kernel sees eth0 interface</li> <li>fc-agent configures interface via DHCP or static</li> </ol>"},{"location":"#image-handling","title":"Image Handling","text":"<p>We use fsify to convert OCI images to ext4 block devices:</p> <pre><code># Manual conversion\nmake convert-image IMAGE=nginx:latest\n\n# Programmatic (via FsifyConverter)\nconverter.Convert(ctx, \"nginx:latest\")\n</code></pre>"},{"location":"#root-filesystem-strategy","title":"Root Filesystem Strategy","text":"<ol> <li>Image pull: Host pulls OCI image (via containerd/skopeo)</li> <li>Convert: fsify creates ext4 block device from layers</li> <li>Attach: Block device attached to VM as virtio-blk</li> <li>Mount: fc-agent mounts as rootfs</li> </ol> <p>This keeps the security boundary clear\u2014images are processed on host, only the final rootfs enters the VM.</p>"},{"location":"#troubleshooting","title":"Troubleshooting","text":""},{"location":"#pod-stuck-in-containercreating","title":"Pod stuck in ContainerCreating","text":"<pre><code># Check sandbox status\nsudo fcctl list\nsudo fcctl inspect &lt;sandbox-id&gt;\n\n# Check agent connectivity\nsudo fcctl exec &lt;sandbox-id&gt; echo \"ping\"\n\n# View logs\nsudo fcctl logs &lt;sandbox-id&gt; -f\n\n# Check metrics for errors\nsudo fcctl metrics | grep error\n</code></pre>"},{"location":"#vm-fails-to-start","title":"VM fails to start","text":"<pre><code># Check KVM access\nls -la /dev/kvm\n\n# Check kernel exists\nls -la /var/lib/fc-cri/vmlinux\n\n# Check rootfs exists\nls -la /var/lib/fc-cri/rootfs/base.ext4\n\n# Run health check\nsudo fcctl health\n</code></pre>"},{"location":"#networking-issues","title":"Networking issues","text":"<pre><code># Check CNI plugins\nls /opt/cni/bin/\n\n# Check CNI config\ncat /etc/cni/net.d/*.conflist\n\n# Check bridge\nip addr show fc-br0\n\n# Test from inside VM\nsudo fcctl exec &lt;sandbox-id&gt; ip addr\nsudo fcctl exec &lt;sandbox-id&gt; ping -c 1 8.8.8.8\n</code></pre>"},{"location":"#clean-up-orphaned-vms","title":"Clean up orphaned VMs","text":"<pre><code># List all VMs\nsudo fcctl list\n\n# Find orphaned (dead/unknown state)\nsudo fcctl cleanup --dry-run\n\n# Clean up\nsudo fcctl cleanup\n</code></pre>"},{"location":"#development","title":"Development","text":""},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>firecracker-cri/\n\u251c\u2500\u2500 cmd/\n\u2502   \u251c\u2500\u2500 containerd-shim-fc-v2/  # Shim binary\n\u2502   \u251c\u2500\u2500 fc-agent/                # Guest agent\n\u2502   \u2514\u2500\u2500 fcctl/                   # Debug CLI\n\u251c\u2500\u2500 pkg/\n\u2502   \u251c\u2500\u2500 domain/                  # Core types\n\u2502   \u251c\u2500\u2500 vm/                      # VM management\n\u2502   \u2502   \u251c\u2500\u2500 manager.go          # Lifecycle\n\u2502   \u2502   \u251c\u2500\u2500 pool.go             # Pre-warming\n\u2502   \u2502   \u251c\u2500\u2500 snapshot.go         # Fast restore\n\u2502   \u2502   \u251c\u2500\u2500 hotplug.go          # Drive attach\n\u2502   \u2502   \u2514\u2500\u2500 jailer.go           # Security\n\u2502   \u251c\u2500\u2500 shim/                    # Shim implementation\n\u2502   \u251c\u2500\u2500 agent/                   # Agent client\n\u2502   \u251c\u2500\u2500 network/                 # CNI integration\n\u2502   \u251c\u2500\u2500 image/                   # OCI \u2192 rootfs\n\u2502   \u251c\u2500\u2500 config/                  # Configuration\n\u2502   \u2514\u2500\u2500 metrics/                 # Prometheus\n\u251c\u2500\u2500 kernel/                      # Kernel build\n\u251c\u2500\u2500 scripts/                     # Helper scripts\n\u251c\u2500\u2500 config/                      # Default configs\n\u2514\u2500\u2500 deploy/kubernetes/           # K8s manifests\n</code></pre>"},{"location":"#building","title":"Building","text":"<pre><code># Build all\nmake build\n\n# Build individual components\nmake shim\nmake agent\n\n# Cross-compile for Linux (from macOS)\nGOOS=linux make build\n\n# Run tests\nmake test\n\n# Run integration tests\nsudo ./scripts/integration-test.sh -v\n</code></pre>"},{"location":"#testing","title":"Testing","text":"<pre><code># Unit tests\ngo test ./...\n\n# Integration tests (requires root, KVM)\nsudo ./scripts/integration-test.sh\n\n# Test specific component\nsudo ./scripts/integration-test.sh -t kernel_boot\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":""},{"location":"#v01-mvp","title":"v0.1 (MVP)","text":"<ul> <li>[x] containerd shim v2 (CreateTask/Start/Stop/Delete)</li> <li>[x] 1 VM per pod sandbox</li> <li>[x] vsock agent (exec, mount, signal)</li> <li>[x] CNI networking (bridge + host-local)</li> <li>[x] RuntimeClass + docs</li> </ul>"},{"location":"#v02","title":"v0.2","text":"<ul> <li>[x] VM pooling</li> <li>[x] Metrics + fcctl</li> <li>[ ] Resilience (restart, cleanup)</li> <li>[ ] CI/CD pipeline</li> </ul>"},{"location":"#v03","title":"v0.3","text":"<ul> <li>[x] Snapshot support (optional)</li> <li>[ ] Multi-arch (arm64)</li> <li>[ ] Conformance tests</li> <li>[ ] PVM support (Pagetable-based VM research)</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Write tests for new functionality</li> <li>Submit a pull request</li> </ol>"},{"location":"#license","title":"License","text":"<p>Apache 2.0</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Firecracker - The microVM engine</li> <li>firecracker-go-sdk - Go SDK</li> <li>containerd - Container runtime</li> <li>fsify - OCI to rootfs conversion</li> </ul>"},{"location":"ARCHITECTURE/","title":"fc-cri Architecture &amp; Design Document","text":""},{"location":"ARCHITECTURE/#executive-summary","title":"Executive Summary","text":"<p>fc-cri is a custom CRI (Container Runtime Interface) runtime that runs containers inside Firecracker microVMs. It's designed as a lightweight alternative to Kata Containers, targeting significantly lower resource overhead while maintaining VM-level isolation.</p>"},{"location":"ARCHITECTURE/#goals","title":"Goals","text":"<ul> <li>Memory: 64-128MB per VM (vs 160MB+ for Kata)</li> <li>Cold Start: &lt;150ms (vs 500ms+ for Kata)</li> <li>Warm Start: &lt;50ms using VM pooling</li> <li>Simplicity: Direct Firecracker integration, minimal abstraction layers</li> </ul>"},{"location":"ARCHITECTURE/#non-goals","title":"Non-Goals","text":"<ul> <li>Full Kata compatibility</li> <li>Support for multiple hypervisors (Firecracker only)</li> <li>Windows containers</li> </ul>"},{"location":"ARCHITECTURE/#background-motivation","title":"Background &amp; Motivation","text":""},{"location":"ARCHITECTURE/#why-not-kata-containers","title":"Why Not Kata Containers?","text":"<p>Kata Containers is the established solution for running containers in VMs on Kubernetes. However, it has significant overhead:</p> Resource Kata Containers Target for fc-cri Memory baseline 160MB+ 64-128MB Guest agent ~50MB (kata-agent) ~2-3MB (fc-agent) Cold start time 500-800ms &lt;150ms Warm start time N/A &lt;50ms Supported hypervisors QEMU, Cloud-Hypervisor, Firecracker Firecracker only <p>Kata's overhead comes from:</p> <ol> <li>Generic VMM abstraction - Supports multiple hypervisors, adding complexity</li> <li>Full-featured guest agent - kata-agent is feature-rich but heavy</li> <li>No VM pooling - Every pod starts a fresh VM</li> <li>Complex storage - Multiple layers of abstraction for image handling</li> </ol>"},{"location":"ARCHITECTURE/#why-firecracker","title":"Why Firecracker?","text":"<p>Firecracker is AWS's microVM hypervisor, used in Lambda and Fargate. Key properties:</p> <ul> <li>Minimal attack surface - Purpose-built for multi-tenant isolation</li> <li>Fast boot - &lt;125ms to kernel boot</li> <li>Low memory - ~5MB VMM overhead</li> <li>Simple API - REST/socket API for VM management</li> <li>No legacy support - No BIOS, no PCI, no USB = smaller kernel</li> </ul>"},{"location":"ARCHITECTURE/#use-cases","title":"Use Cases","text":"<ol> <li>Multi-tenant SaaS - Run untrusted customer code with VM isolation</li> <li>CI/CD pipelines - Isolated build environments</li> <li>Serverless platforms - Fast-starting isolated execution environments</li> <li>Compliance workloads - When container isolation isn't sufficient</li> </ol>"},{"location":"ARCHITECTURE/#architecture-overview","title":"Architecture Overview","text":""},{"location":"ARCHITECTURE/#system-context","title":"System Context","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            Kubernetes Cluster                            \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                           Control Plane                           \u2502   \u2502\n\u2502  \u2502                                                                   \u2502   \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502  \u2502   \u2502 API Server  \u2502   \u2502 Scheduler   \u2502   \u2502 Controller Manager  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                    \u2502                                     \u2502\n\u2502                                    \u2502 Schedule Pod with                   \u2502\n\u2502                                    \u2502 runtimeClassName: firecracker       \u2502\n\u2502                                    \u25bc                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                          Worker Node                              \u2502   \u2502\n\u2502  \u2502                                                                   \u2502   \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502  \u2502   \u2502                       kubelet                            \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502                          \u2502                               \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502                     CRI (gRPC)                           \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502                          \u2502                               \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502                          \u25bc                               \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502                  containerd                      \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502                       \u2502                          \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502              Runtime Selection                   \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502                       \u2502                          \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502         \u2502                           \u2502           \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502         \u25bc                           \u25bc           \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502   \u2502   runc   \u2502              \u2502  fc-cri     \u2502    \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502   \u2502 (default)\u2502              \u2502   shim      \u2502    \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2502                                    \u2502           \u2502   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502                                        \u2502               \u2502   \u2502   \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502  \u2502                                            \u2502                   \u2502   \u2502\n\u2502  \u2502                                            \u25bc                   \u2502   \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502  \u2502   \u2502                   Firecracker VMM                       \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502  \u2502                    microVM                        \u2502  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502  \u2502                                                   \u2502  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502  \u2502   \u2502  fc-agent   \u2502\u25c4\u2500\u2500\u2500\u2500\u25ba\u2502  Container (runc)    \u2502  \u2502  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502  \u2502          \u25b2                                        \u2502  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502             \u2502 vsock                                      \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502             \u25bc                                            \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                     \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502      \u2502  VM Pool    \u2502 (pre-warmed VMs)                    \u2502   \u2502   \u2502\n\u2502  \u2502   \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                     \u2502   \u2502   \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#component-architecture","title":"Component Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              fc-cri                                      \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                    containerd-shim-fc-v2                            \u2502 \u2502\n\u2502  \u2502                                                                     \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502   Shim Service   \u2502  \u2502   VM Manager     \u2502  \u2502   Agent Client   \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502                  \u2502  \u2502                  \u2502  \u2502                  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - Task lifecycle \u2502  \u2502 - Create/Stop VM \u2502  \u2502 - JSON-RPC/vsock \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - Event publish  \u2502  \u2502 - Snapshot mgmt  \u2502  \u2502 - Container ops  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - State tracking \u2502  \u2502 - Resource cfg   \u2502  \u2502 - Exec/Attach    \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2502           \u2502                     \u2502                     \u2502           \u2502 \u2502\n\u2502  \u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502 \u2502\n\u2502  \u2502                                 \u2502                                  \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502                         VM Pool                               \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502                                                               \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u2502 Warm VM \u2502 \u2502 Warm VM \u2502 \u2502 Warm VM \u2502 \u2502 Warm VM \u2502 \u2502 Warm VM \u2502\u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502 \u2502 \u2502\n\u2502  \u2502  \u2502                                                               \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  - Acquire() \u2192 O(1) VM retrieval                             \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  - Release() \u2192 Return to pool or destroy                     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  - Auto-replenish background goroutine                       \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502  - Idle cleanup (configurable max idle time)                 \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2502                                                                     \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502  Network (CNI)   \u2502  \u2502  Image Service   \u2502  \u2502  Config Manager  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502                  \u2502  \u2502                  \u2502  \u2502                  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - TAP devices    \u2502  \u2502 - OCI pull       \u2502  \u2502 - TOML config    \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - Bridge setup   \u2502  \u2502 - Layer flatten  \u2502  \u2502 - Defaults       \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - IP assignment  \u2502  \u2502 - ext4 creation  \u2502  \u2502 - Validation     \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                          fc-agent (in VM)                           \u2502 \u2502\n\u2502  \u2502                                                                     \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502  \u2502   vsock Server   \u2502  \u2502  Container Mgr   \u2502  \u2502   Stats/Cgroups  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502                  \u2502  \u2502                  \u2502  \u2502                  \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - JSON-RPC proto \u2502  \u2502 - runc create    \u2502  \u2502 - CPU usage      \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - Request router \u2502  \u2502 - runc start     \u2502  \u2502 - Memory usage   \u2502 \u2502 \u2502\n\u2502  \u2502  \u2502 - Conn handling  \u2502  \u2502 - runc exec      \u2502  \u2502 - I/O stats      \u2502 \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#domain-model","title":"Domain Model","text":"<p>Following domain-driven design principles, the core domain is modeled around these key concepts:</p>"},{"location":"ARCHITECTURE/#aggregate-roots","title":"Aggregate Roots","text":""},{"location":"ARCHITECTURE/#sandbox-pod-sandbox-microvm","title":"Sandbox (Pod Sandbox / microVM)","text":"<p>The <code>Sandbox</code> is the aggregate root representing a Firecracker microVM that hosts one or more containers.</p> <pre><code>type Sandbox struct {\n    // Identity\n    ID        string\n    Name      string\n    Namespace string\n\n    // VM State\n    State       SandboxState  // Pending \u2192 Ready \u2192 Stopped\n    VM          *firecracker.Machine\n    VMConfig    VMConfig\n\n    // Communication\n    VsockPath   string\n    VsockCID    uint32\n    AgentConn   net.Conn\n\n    // Networking\n    NetworkNamespace string\n    IP               net.IP\n\n    // Containers within this sandbox\n    Containers map[string]*Container\n}\n</code></pre>"},{"location":"ARCHITECTURE/#container","title":"Container","text":"<p>A <code>Container</code> represents a container running inside a Sandbox (microVM).</p> <pre><code>type Container struct {\n    ID        string\n    SandboxID string\n    Name      string\n    Image     string\n\n    State      ContainerState  // Created \u2192 Running \u2192 Exited\n    PID        int\n    ExitCode   int32\n\n    // Configuration\n    Command    []string\n    Env        []string\n    Mounts     []Mount\n    Resources  ResourceConfig\n}\n</code></pre>"},{"location":"ARCHITECTURE/#value-objects","title":"Value Objects","text":""},{"location":"ARCHITECTURE/#vmconfig","title":"VMConfig","text":"<p>Immutable configuration for creating a Firecracker VM.</p> <pre><code>type VMConfig struct {\n    VcpuCount    int64   // Default: 1\n    MemoryMB     int64   // Default: 128\n    KernelPath   string\n    KernelArgs   string\n    RootDrive    DriveConfig\n    NetworkMode  string  // \"cni\" or \"none\"\n    VsockEnabled bool\n}\n</code></pre>"},{"location":"ARCHITECTURE/#domain-services","title":"Domain Services","text":"Service Responsibility <code>VMManager</code> Create, stop, destroy Firecracker VMs <code>VMPool</code> Pre-warm VMs for fast acquisition <code>AgentClient</code> Communicate with guest agent via vsock <code>NetworkService</code> CNI-based network setup and teardown <code>ImageService</code> OCI image pull and block device conversion"},{"location":"ARCHITECTURE/#key-design-decisions","title":"Key Design Decisions","text":""},{"location":"ARCHITECTURE/#1-containerd-shim-v2-not-full-cri-server","title":"1. containerd Shim v2 (Not Full CRI Server)","text":"<p>Decision: Implement a containerd shim rather than a standalone CRI server.</p> <p>Rationale:</p> <ul> <li>containerd handles CRI protocol, image management, and storage</li> <li>Shim only handles runtime-specific logic</li> <li>Less code to maintain, better integration</li> <li>containerd manages shim lifecycle automatically</li> </ul> <p>Trade-off: Tightly coupled to containerd (can't use with CRI-O directly)</p>"},{"location":"ARCHITECTURE/#2-vm-pooling-for-fast-starts","title":"2. VM Pooling for Fast Starts","text":"<p>Decision: Pre-warm VMs and maintain a pool of ready-to-use instances.</p> <p>Rationale:</p> <ul> <li>VM creation is the slowest part (~150ms even with Firecracker)</li> <li>Pool provides O(1) VM acquisition</li> <li>Enables &lt;50ms pod start times</li> </ul> <p>Implementation:</p> <pre><code>type Pool struct {\n    available chan *Sandbox  // Ready VMs\n    inUse     map[string]*Sandbox\n    config    PoolConfig\n}\n\nfunc (p *Pool) Acquire(ctx context.Context, config VMConfig) (*Sandbox, error) {\n    select {\n    case sandbox := &lt;-p.available:\n        // Got pre-warmed VM - customize and return\n        return p.customizeVM(sandbox, config)\n    default:\n        // Pool empty - create fresh\n        return p.manager.CreateVM(ctx, config)\n    }\n}\n</code></pre> <p>Configuration:</p> <pre><code>[pool]\nenabled = true\nsize = 5          # VMs to keep ready\nmin_size = 2      # Minimum to maintain\nmax_idle_time = \"5m\"\n</code></pre>"},{"location":"ARCHITECTURE/#3-minimal-guest-agent","title":"3. Minimal Guest Agent","text":"<p>Decision: Build a custom minimal agent instead of using kata-agent.</p> <p>Rationale:</p> <ul> <li>kata-agent is ~50MB, ours is ~2-3MB</li> <li>Simple JSON-RPC protocol over vsock</li> <li>Only implements what we need</li> <li>Static binary, no runtime dependencies</li> </ul> <p>Protocol:</p> <pre><code>// Request\n{\"id\": 1, \"method\": \"create_container\", \"params\": {\"id\": \"abc\", \"bundle\": \"/...\"}}\n\n// Response\n{\"id\": 1, \"result\": {\"status\": \"created\"}}\n</code></pre> <p>Supported Methods:</p> <ul> <li><code>ping</code> - Health check</li> <li><code>create_container</code> - Create container via runc</li> <li><code>start_container</code> - Start container, return PID</li> <li><code>stop_container</code> - Stop with timeout, then SIGKILL</li> <li><code>remove_container</code> - Delete container</li> <li><code>exec_sync</code> - Synchronous exec</li> <li><code>get_stats</code> - Cgroup statistics</li> </ul>"},{"location":"ARCHITECTURE/#4-block-device-storage-not-overlayfs","title":"4. Block Device Storage (Not Overlayfs)","text":"<p>Decision: Convert OCI images to ext4 block devices.</p> <p>Rationale:</p> <ul> <li>Firecracker doesn't support filesystem sharing (no 9p, no virtiofs)</li> <li>Block devices (virtio-blk) are fast and simple</li> <li>Sparse files minimize disk usage</li> </ul> <p>Flow:</p> <pre><code>OCI Image \u2192 Pull layers \u2192 Flatten \u2192 Create ext4 \u2192 Attach to VM as /dev/vda\n</code></pre> <p>Future Optimization: Use device mapper thin provisioning for copy-on-write efficiency.</p>"},{"location":"ARCHITECTURE/#5-minimal-kernel-configuration","title":"5. Minimal Kernel Configuration","text":"<p>Decision: Build a custom minimal kernel (~5MB uncompressed).</p> <p>Rationale:</p> <ul> <li>Stock kernels are 30-50MB</li> <li>We only need: virtio, vsock, ext4, cgroups, namespaces, netfilter</li> <li>Faster boot, smaller memory footprint</li> </ul> <p>Trade-offs:</p> <ul> <li>Reduced Compatibility: Missing drivers for XFS, ZFS, SCTP, and specialized hardware.</li> <li>Mitigation: Users can supply their own kernel via <code>config.toml</code> (see Operations Guide).</li> </ul> <p>Key Config:</p> <pre><code>CONFIG_VIRTIO_MMIO=y      # Firecracker uses MMIO, not PCI\nCONFIG_VIRTIO_BLK=y       # Block devices\nCONFIG_VIRTIO_NET=y       # Networking\nCONFIG_VIRTIO_VSOCKETS=y  # Host communication\nCONFIG_EXT4_FS=y          # Rootfs\nCONFIG_OVERLAY_FS=y       # Container layers\nCONFIG_CGROUPS=y          # Resource limits\nCONFIG_NAMESPACES=y       # Container isolation\nCONFIG_PCI=n              # Not needed\nCONFIG_USB_SUPPORT=n      # Not needed\nCONFIG_SOUND=n            # Not needed\n</code></pre>"},{"location":"ARCHITECTURE/#implementation-status","title":"Implementation Status","text":""},{"location":"ARCHITECTURE/#completed-components","title":"Completed Components","text":"Component Description Domain Model Core entities, value objects, and service interfaces. VM Manager Lifecycle management (create, stop, destroy) using firecracker-go-sdk. VM Pool Pre-warming, acquisition, release, and auto-replenishment logic. Shim Service Implementation of containerd shim v2 task API. Agent Client Host-side JSON-RPC client for guest communication. Guest Agent Minimal static binary handling vsock communication and runc integration. CNI Network Network namespace management and CNI plugin invocation. Image Service OCI image pull and conversion to ext4 block devices (fsify). Hot-Attach Dynamic attachment of workload rootfs to pooled VMs. Snapshot Restore Fast VM restoration from memory snapshots. Jailer Production security hardening (chroot, cgroups, seccomp). Metrics Prometheus metrics for pool stats, latencies, and errors. CLI Tool <code>fcctl</code> for inspection and debugging."},{"location":"ARCHITECTURE/#future-work","title":"Future Work","text":"Component Priority Notes Devmapper High Alternative storage backend for thin provisioning. ARM64 Medium Support for Graviton/Ampere instances. GPU Low Passthrough support for ML workloads. PVM Low Pagetable-based Virtual Machine (Research). Support for running without nested virtualization."},{"location":"ARCHITECTURE/#file-structure","title":"File Structure","text":"<pre><code>firecracker-cri/\n\u251c\u2500\u2500 cmd/\n\u2502   \u251c\u2500\u2500 containerd-shim-fc-v2/\n\u2502   \u2502   \u2514\u2500\u2500 main.go              # Shim entry point\n\u2502   \u2514\u2500\u2500 fc-agent/\n\u2502       \u2514\u2500\u2500 main.go              # Guest agent (static binary)\n\u2502\n\u251c\u2500\u2500 pkg/\n\u2502   \u251c\u2500\u2500 domain/\n\u2502   \u2502   \u2514\u2500\u2500 types.go             # Core domain model\n\u2502   \u251c\u2500\u2500 vm/\n\u2502   \u2502   \u251c\u2500\u2500 manager.go           # VM lifecycle management\n\u2502   \u2502   \u2514\u2500\u2500 pool.go              # Pre-warming pool\n\u2502   \u251c\u2500\u2500 shim/\n\u2502   \u2502   \u2514\u2500\u2500 service.go           # containerd shim v2 service\n\u2502   \u251c\u2500\u2500 agent/\n\u2502   \u2502   \u2514\u2500\u2500 client.go            # Guest agent client\n\u2502   \u251c\u2500\u2500 network/\n\u2502   \u2502   \u2514\u2500\u2500 cni.go               # CNI integration\n\u2502   \u2514\u2500\u2500 image/\n\u2502       \u2514\u2500\u2500 rootfs.go            # OCI to block device\n\u2502\n\u251c\u2500\u2500 kernel/\n\u2502   \u251c\u2500\u2500 config-minimal           # Kernel configuration\n\u2502   \u2514\u2500\u2500 build.sh                 # Kernel build script\n\u2502\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 fc-cri.toml              # Runtime configuration\n\u2502   \u2514\u2500\u2500 containerd-fc.toml       # containerd integration\n\u2502\n\u251c\u2500\u2500 deploy/\n\u2502   \u2514\u2500\u2500 kubernetes/\n\u2502       \u251c\u2500\u2500 runtime-class.yaml   # Kubernetes RuntimeClass\n\u2502       \u2514\u2500\u2500 example-pod.yaml     # Usage examples\n\u2502\n\u251c\u2500\u2500 scripts/\n\u2502   \u2514\u2500\u2500 create-rootfs.sh         # Base rootfs creation\n\u2502\n\u251c\u2500\u2500 docs/\n\u2502   \u2514\u2500\u2500 ARCHITECTURE.md          # This document\n\u2502\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"ARCHITECTURE/#getting-started","title":"Getting Started","text":""},{"location":"ARCHITECTURE/#prerequisites","title":"Prerequisites","text":"<pre><code># Required\n- Linux with KVM support (check: ls /dev/kvm)\n- containerd 1.6+\n- Go 1.22+\n- Root access for installation\n\n# Optional\n- Docker (for building rootfs)\n- crictl (for testing)\n</code></pre>"},{"location":"ARCHITECTURE/#build-install","title":"Build &amp; Install","text":"<pre><code># Clone the repository\ngit clone https://github.com/pipeops/firecracker-cri.git\ncd firecracker-cri\n\n# Build binaries\nmake build\n\n# Build kernel (one-time, ~10 minutes)\nmake kernel\n\n# Create base rootfs\nmake rootfs\n\n# Install\nsudo make install\n\n# Restart containerd\nsudo systemctl restart containerd\n</code></pre>"},{"location":"ARCHITECTURE/#test-with-kubernetes","title":"Test with Kubernetes","text":"<pre><code># Apply RuntimeClass\nkubectl apply -f deploy/kubernetes/runtime-class.yaml\n\n# Label node as fc-cri enabled\nkubectl label node &lt;node-name&gt; fc-cri.io/enabled=true\n\n# Run a test pod\nkubectl apply -f deploy/kubernetes/example-pod.yaml\n\n# Check pod status\nkubectl get pod secure-workload\n\n# Verify it's running in a Firecracker VM\nkubectl describe pod secure-workload | grep -A5 \"Events\"\n</code></pre>"},{"location":"ARCHITECTURE/#performance-tuning","title":"Performance Tuning","text":""},{"location":"ARCHITECTURE/#pool-sizing","title":"Pool Sizing","text":"<pre><code>[pool]\nsize = 10        # For high-throughput: increase\nmin_size = 5     # For consistent latency: increase\nmax_idle_time = \"10m\"  # For cost savings: decrease\n</code></pre>"},{"location":"ARCHITECTURE/#memory-optimization","title":"Memory Optimization","text":"<pre><code>[vm]\nmemory_mb = 64   # Minimum for small workloads\n# memory_mb = 128  # Default, good for most\n# memory_mb = 256  # For memory-heavy apps\n</code></pre>"},{"location":"ARCHITECTURE/#kernel-args","title":"Kernel Args","text":"<pre><code>kernel_args = \"console=ttyS0 reboot=k panic=1 pci=off quiet loglevel=0\"\n# Add 'quiet loglevel=0' for faster boot (less console output)\n</code></pre>"},{"location":"ARCHITECTURE/#security-considerations","title":"Security Considerations","text":""},{"location":"ARCHITECTURE/#vm-isolation","title":"VM Isolation","text":"<ul> <li>Each pod runs in a separate Firecracker microVM</li> <li>Hardware-level isolation via KVM</li> <li>Separate kernel, memory space, and filesystem</li> </ul>"},{"location":"ARCHITECTURE/#jailer-production","title":"Jailer (Production)","text":"<p>Enable the jailer for additional security:</p> <pre><code>[jailer]\nenabled = true\nuid = 1000\ngid = 1000\nchroot_base_dir = \"/srv/jailer\"\n</code></pre> <p>The jailer provides:</p> <ul> <li>Chroot isolation for Firecracker process</li> <li>Seccomp filtering</li> <li>Cgroup enforcement</li> <li>Dropped privileges</li> </ul>"},{"location":"ARCHITECTURE/#network-isolation","title":"Network Isolation","text":"<ul> <li>Each VM gets its own network namespace</li> <li>CNI handles network policy enforcement</li> <li>No shared network stack with host</li> </ul>"},{"location":"ARCHITECTURE/#comparison-with-alternatives","title":"Comparison with Alternatives","text":"Feature fc-cri Kata Containers gVisor Isolation VM VM Syscall filtering Memory overhead 64-128MB 160MB+ 50-100MB Cold start &lt;150ms 500ms+ &lt;100ms Compatibility High High Medium Hypervisor Firecracker Multiple None Complexity Low High Medium Production ready In progress Yes Yes"},{"location":"ARCHITECTURE/#contributing","title":"Contributing","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Write tests</li> <li>Submit a pull request</li> </ol>"},{"location":"ARCHITECTURE/#code-style","title":"Code Style","text":"<ul> <li>Follow Go conventions</li> <li>Domain-driven design principles</li> <li>Clear separation of concerns</li> <li>Comprehensive error handling</li> </ul>"},{"location":"ARCHITECTURE/#references","title":"References","text":"<ul> <li>Firecracker</li> <li>firecracker-go-sdk</li> <li>containerd Shim v2</li> <li>Kata Containers</li> <li>CRI Specification</li> </ul>"},{"location":"ARCHITECTURE/#license","title":"License","text":"<p>Apache 2.0</p>"},{"location":"comparison/","title":"Comparison: Daemon vs. Shim Architecture","text":"<p>The Firecracker ecosystem offers two main approaches to running microVMs in Kubernetes: the Daemon Model (used by AWS's <code>firecracker-containerd</code>) and the Shim Model (used by <code>firecracker-shim</code>).</p> <p>This guide explains the architectural differences, trade-offs, and why we chose the Shim model for this project.</p>"},{"location":"comparison/#at-a-glance","title":"At a Glance","text":"Feature Daemon (<code>firecracker-containerd</code>) Shim (<code>firecracker-shim</code>) Architecture Centralized Monolith Decentralized Processes (1 per pod) Compatibility Custom: Often needs patched <code>containerd</code> Standard: Works with upstream <code>containerd</code> Blast Radius High: Daemon crash affects all VMs Low: Shim crash affects only one pod Storage Complex Device Mapper (Required) Simple File-backed (ext4) Memory Overhead Lowest (Shared runtime) Low (~10MB overhead per pod) Debugging Difficult (Shared logs, opaque state) Native (Process tree, <code>kill</code>, <code>ps</code>) Setup High Complexity (Custom LVM/storage) Plug-and-Play (Binary + Config) Best For Hyperscale Lambda-like density Kubernetes Pods, CI Runners, SaaS"},{"location":"comparison/#1-the-daemon-model-aws","title":"1. The Daemon Model (AWS)","text":"<p>AWS built <code>firecracker-containerd</code> with a focus on extreme density (thousands of functions per node). To achieve this, they centralized management into a single long-running daemon.</p>"},{"location":"comparison/#why-use-a-daemon","title":"Why use a Daemon?","text":"<ul> <li>Memory Efficiency: By sharing the Go runtime across all management threads, the per-VM overhead is negligible (kilobytes).</li> <li>Centralized Storage: It acts as the authority for Device Mapper (devmapper), preventing race conditions when managing block devices at scale.</li> <li>Resilience: It runs independently of <code>containerd</code>, so <code>containerd</code> upgrades don't affect running VMs.</li> </ul>"},{"location":"comparison/#the-drawbacks","title":"The Drawbacks","text":"<ul> <li>Specialized Binaries: It relies on a control plugin compiled into containerd, often requiring you to replace your system's standard <code>containerd</code> with a specialized build.</li> <li>Single Point of Failure: If the daemon crashes, deadlocks, or is killed by OOM, every microVM on the node is orphaned or lost.</li> <li>Operational Complexity: It requires a specific storage setup (LVM thin pools, devmapper) that is difficult to configure and debug compared to standard overlay filesystems.</li> <li>Debugging: Identifying why one specific pod failed involves sifting through the logs of a daemon handling hundreds of concurrent operations.</li> </ul>"},{"location":"comparison/#2-the-shim-model-us","title":"2. The Shim Model (Us)","text":"<p><code>firecracker-shim</code> adopts the Containerd Shim v2 architecture, which has become the industry standard for runtimes like <code>runc</code>, <code>gvisor</code>, and <code>kata-containers</code>.</p>"},{"location":"comparison/#why-use-a-shim","title":"Why use a Shim?","text":"<ul> <li>Isolation (Blast Radius): Each pod gets its own shim process. If a shim crashes due to a bug or memory issue, only that specific pod fails. The rest of the node remains stable.</li> <li>Kubernetes Native Debugging: The process tree reflects the pod structure.   <pre><code>containerd\n \u2514\u2500 containerd-shim-fc-v2 (Pod A)\n     \u2514\u2500 firecracker (VM A)\n \u2514\u2500 containerd-shim-fc-v2 (Pod B)\n     \u2514\u2500 firecracker (VM B)\n</code></pre>   You can identify, trace, or kill individual pods using standard Linux tools (<code>ps</code>, <code>top</code>, <code>kill</code>).</li> <li>Simplicity: We replaced complex device mapper requirements with simple file-backed images (<code>.ext4</code>). This allows the runtime to work on any Linux machine without specialized storage configuration.</li> <li>Compatibility: Because we implement the standard Shim v2 API, we work with unmodified, upstream <code>containerd</code> (v1.7+). No need to replace your existing container runtime binaries.</li> </ul>"},{"location":"comparison/#the-drawbacks_1","title":"The Drawbacks","text":"<ul> <li>Slightly Higher Memory: Each shim process has its own Go runtime overhead (~10-15MB). On a node with 100 pods, this uses ~1.5GB of RAM for management. We consider this an acceptable trade-off for the stability and simplicity gained.</li> </ul>"},{"location":"comparison/#conclusion","title":"Conclusion","text":"<p>We built <code>firecracker-shim</code> because we believe the Shim Model is superior for general-purpose Kubernetes workloads.</p> <ul> <li>Choose the Daemon (<code>firecracker-containerd</code>) if you are building a Lambda clone with 5,000+ tiny functions per node and possess a dedicated storage engineering team.</li> <li>Choose the Shim (<code>firecracker-shim</code>) if you want secure, isolated Kubernetes pods with standard operational tooling, high reliability, and easy setup.</li> </ul>"},{"location":"compatibility/","title":"Compatibility Matrix","text":"<p>This document tracks the compatibility of <code>firecracker-shim</code> with various upstream components and environment versions.</p>"},{"location":"compatibility/#core-components","title":"Core Components","text":"Component Tested Versions Minimum Required Notes Kubernetes 1.24 - 1.29 1.24+ Requires <code>RuntimeClass</code> support. containerd 1.7.0+ 1.7.0+ Shim v2 API is stable since 1.6, but we validate on 1.7. Firecracker v1.6.0 v1.3.0 Uses <code>firecracker-go-sdk</code> compatibility. Linux Kernel (Host) 5.10, 6.1 4.14 Requires KVM and <code>vhost_vsock</code> module."},{"location":"compatibility/#cni-plugins","title":"CNI Plugins","text":"<p>We support standard CNI plugins via the bridge setup.</p> Plugin Status Notes bridge [Supported] Default configuration. ptp [Supported] Point-to-point setup works well. flannel [Supported] Standard overlay works via bridge. calico [Supported] Requires standard CNI config (not eBPF mode). aws-vpc-cni [Experimental] Requires specific interface handling inside VM. cilium [Experimental] eBPF acceleration features are not passed through to VM."},{"location":"compatibility/#guest-kernels","title":"Guest Kernels","text":"<p>The guest kernel running inside the microVM must support virtio drivers.</p> Kernel Source Version Status Notes PipeOps Minimal 6.1.x [Default] ~5MB, optimized for speed. No module support. AWS Firecracker 5.10.x [Compatible] Official AWS kernel. Ubuntu / Generic 5.x+ [Heavy] Works but increases boot time significantly (~1-2s)."},{"location":"compatibility/#architecture","title":"Architecture","text":"Arch Status Notes AMD64 (x86_64) [Stable] Primary development platform. ARM64 (aarch64) [Planned] Requires different kernel/rootfs and Firecracker binary. PVM (x86_64) [Research] Software-based virtualization. No nested virt required."},{"location":"compatibility/#pvm-experimental","title":"PVM (Experimental)","text":"<p>Pagetable-based Virtual Machine (PVM) is a software-based virtualization framework that enables running secure containers without hardware-assisted nested virtualization.</p>"},{"location":"compatibility/#requirements","title":"Requirements","text":"Requirement Details Host Kernel Linux 6.7+ with PVM RFC patchset (provides <code>kvm-pvm.ko</code>). Guest Kernel Must be compiled as a Position-Independent Executable (PIE). Guest Mode Runs in hardware Ring 3 (user mode). Hardware x86_64 CPU with support for Shadow Paging and PCID."},{"location":"compatibility/#limitations","title":"Limitations","text":"<ul> <li>MMU Performance: Uses Shadow Paging instead of EPT/NPT, causing overhead for frequent page table changes (e.g., <code>fork()</code>).</li> <li>Kernel Features: No support for LDT (Local Descriptor Table).</li> <li>Security Emulation: SMAP/SMEP must be emulated using Memory Protection Keys (PKU) and NX bits.</li> <li>CPU Features: PMU (Performance Monitoring Unit) virtualization is limited/not fully implemented.</li> </ul>"},{"location":"existing-clusters/","title":"Running on Existing Clusters","text":"<p>This guide explains how to install and configure <code>firecracker-shim</code> on an existing Kubernetes cluster (e.g., EKS, GKE, bare metal).</p>"},{"location":"existing-clusters/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure your worker nodes meet these requirements:</p> <ol> <li>Virtualization Support: Nodes must support KVM.<ul> <li>Bare Metal: Enabled in BIOS.</li> <li>Cloud VMs: Must support nested virtualization (e.g., AWS <code>.metal</code> instances, GCP nested virtualization).</li> <li>Check with: <code>ls -la /dev/kvm</code></li> </ul> </li> <li>Container Runtime: Nodes must use containerd (v1.6+).<ul> <li>Docker shim (dockershim) is not supported.</li> <li>CRI-O is conceptually compatible but this guide focuses on containerd configuration.</li> </ul> </li> <li>OS: Linux kernel 4.14+ (recommended 5.10+).</li> </ol>"},{"location":"existing-clusters/#installation-methods","title":"Installation Methods","text":"<p>Choose one of the following methods to install the runtime components on your nodes.</p>"},{"location":"existing-clusters/#method-1-daemonset-installer-recommended","title":"Method 1: DaemonSet Installer (Recommended)","text":"<p>We provide a DaemonSet that runs a privileged pod on every node to install the binaries, configuration, and assets.</p> <p>1. Apply the Installer Manifest</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/PipeOpsHQ/firecracker-shim/main/deploy/installer/daemonset.yaml\n</code></pre> <p>2. Wait for Installation</p> <p>The installer pod will: 1.  Check for KVM support (and sleep if missing). 2.  Copy binaries (<code>containerd-shim-fc-v2</code>, <code>fc-agent</code>, <code>firecracker</code>) to <code>/usr/local/bin</code>. 3.  Install the kernel and rootfs to <code>/var/lib/fc-cri</code>. 4.  Update containerd configuration. 5.  Restart containerd (Note: This may cause a momentary disruption to pod scheduling on the node).</p> <p>Check the logs to verify success:</p> <pre><code>kubectl -n kube-system logs -l app=firecracker-shim-installer\n</code></pre>"},{"location":"existing-clusters/#method-2-manual-installation-ansibleuser-data","title":"Method 2: Manual Installation (Ansible/User Data)","text":"<p>If you prefer to manage nodes via configuration management (Ansible, Chef, Terraform user_data), follow these steps for each node.</p> <p>1. Install Binaries</p> <p>Download the latest release and extract to <code>/usr/local/bin</code>:</p> <pre><code>VERSION=\"v0.1.0\"\nwget https://github.com/PipeOpsHQ/firecracker-shim/releases/download/${VERSION}/firecracker-shim-linux-amd64.tar.gz\ntar xf firecracker-shim-linux-amd64.tar.gz -C /usr/local/bin/\n</code></pre> <p>2. Install Assets</p> <p>You need the guest kernel and base rootfs.</p> <pre><code>mkdir -p /var/lib/fc-cri/rootfs\n# Download or build these assets (see Build Guide)\ncp vmlinux /var/lib/fc-cri/\ncp base.ext4 /var/lib/fc-cri/rootfs/\n</code></pre> <p>3. Configure Runtime</p> <p>Create the config file:</p> <pre><code>mkdir -p /etc/fc-cri\ncp config.toml /etc/fc-cri/\n</code></pre> <p>4. Configure containerd</p> <p>Add the runtime plugin configuration. If your containerd supports <code>config.d</code>:</p> <pre><code># /etc/containerd/config.d/firecracker.toml\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.firecracker]\n  runtime_type = \"io.containerd.firecracker.v2\"\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.firecracker.options]\n    ConfigPath = \"/etc/fc-cri/config.toml\"\n</code></pre> <p>Then restart containerd:</p> <pre><code>systemctl restart containerd\n</code></pre>"},{"location":"existing-clusters/#cluster-configuration","title":"Cluster Configuration","text":"<p>Once the nodes have the software installed, tell Kubernetes how to use it.</p>"},{"location":"existing-clusters/#1-create-runtimeclass","title":"1. Create RuntimeClass","text":"<p>This defines the <code>firecracker</code> runtime class.</p> <pre><code># runtime-class.yaml\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: firecracker\nhandler: firecracker  # Must match the name in containerd config\noverhead:\n  podFixed:\n    memory: \"64Mi\"  # Overhead reservation per VM\n    cpu: \"100m\"\nscheduling:\n  nodeSelector:\n    fc-cri.io/enabled: \"true\" # Optional: restrict to specific nodes\n</code></pre> <pre><code>kubectl apply -f runtime-class.yaml\n</code></pre>"},{"location":"existing-clusters/#2-label-nodes","title":"2. Label Nodes","text":"<p>If you are using the <code>nodeSelector</code> in the RuntimeClass, label the compatible nodes:</p> <pre><code>kubectl label node &lt;node-name&gt; fc-cri.io/enabled=true\n</code></pre>"},{"location":"existing-clusters/#running-workloads","title":"Running Workloads","text":"<p>Deploy a pod using the <code>runtimeClassName</code>.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: secure-nginx\nspec:\n  runtimeClassName: firecracker\n  containers:\n    - name: nginx\n      image: nginx:alpine\n</code></pre> <pre><code>kubectl apply -f pod.yaml\n</code></pre> <p>Verify it is running:</p> <pre><code>kubectl get pod secure-nginx -o wide\n</code></pre> <p>You can also use <code>fcctl</code> on the node to verify the VM is running:</p> <pre><code># On the worker node\nsudo fcctl list\n</code></pre>"},{"location":"existing-clusters/#troubleshooting","title":"Troubleshooting","text":""},{"location":"existing-clusters/#runtimehandler-not-found-error","title":"\"RuntimeHandler not found\" Error","text":"<p>Symptom: Pod stays in <code>ContainerCreating</code> with error <code>RuntimeHandler \"firecracker\" not supported</code>.</p> <p>Fix: 1.  Verify containerd config has the <code>[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.firecracker]</code> section. 2.  Verify <code>systemctl restart containerd</code> was run. 3.  Check <code>containerd</code> logs: <code>journalctl -u containerd -f</code>.</p>"},{"location":"existing-clusters/#kvm-not-available","title":"\"KVM not available\"","text":"<p>Symptom: <code>fcctl health</code> shows KVM error or pod fails to start.</p> <p>Fix: 1.  Check permissions: <code>ls -la /dev/kvm</code>. 2.  Ensure the user running the process (usually root for containerd) has access. 3.  On cloud instances, ensure you are using a supported instance type (e.g., AWS <code>i3.metal</code>).</p>"},{"location":"existing-clusters/#image-pull-errors","title":"Image Pull Errors","text":"<p>Symptom: Pod fails with image pull or unpack errors.</p> <p>Fix: The shim relies on <code>fsify</code> and <code>skopeo</code> to convert images. Ensure these tools are installed and in the PATH if they are not bundled in your installer image.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#comparisons","title":"Comparisons","text":""},{"location":"faq/#how-is-this-different-from-firecracker-containerd","title":"How is this different from <code>firecracker-containerd</code>?","text":"<p>AWS's <code>firecracker-containerd</code> uses a daemon-centric architecture designed for hyperscale density (thousands of microVMs per node). It acts as a central manager for all VMs and often requires complex storage setups (Device Mapper) and sometimes a patched <code>containerd</code>.</p> <p>firecracker-shim uses the modern Shim v2 architecture:</p> <ul> <li>Standard Integration: We work with unmodified, upstream <code>containerd</code>.</li> <li>Failure Isolation: Each pod has its own shim process. If a shim crashes, only that specific pod is affected\u2014not the entire node.</li> <li>Operational Simplicity: We use simple file-backed images (<code>.ext4</code>) and standard CNI networking. You don't need to be a storage engineer to run it.</li> </ul> <p>Choose <code>firecracker-containerd</code> if you are building an AWS Lambda competitor with thousands of functions per server. Choose <code>firecracker-shim</code> if you want secure Kubernetes pods with the ease of use of standard containers.</p>"},{"location":"faq/#how-is-this-different-from-kata-containers","title":"How is this different from Kata Containers?","text":"<p>Kata Containers is a mature project that supports multiple hypervisors (QEMU, Cloud Hypervisor, Firecracker). While powerful, this flexibility creates abstraction layers that add weight.</p> <p>firecracker-shim is opinionated and optimized:</p> <ul> <li>Single Focus: We only support Firecracker. No abstraction layers for QEMU.</li> <li>Lighter: Our per-pod memory overhead is ~64MB vs Kata's ~160MB+.</li> <li>Simpler: Our agent is a static ~2MB binary, not a complex systemd-based guest image.</li> </ul>"},{"location":"faq/#how-is-this-different-from-gvisor","title":"How is this different from gVisor?","text":"<p>gVisor uses syscall emulation (a kernel written in Go running in userspace) to isolate containers. Firecracker uses hardware virtualization (KVM).</p> <ul> <li>Security: Both provide excellent isolation. Hardware virtualization (KVM) is generally considered the \"gold standard\" boundary.</li> <li>Performance: gVisor can be faster for some operations but slower for syscall-heavy workloads (network/IO). Firecracker behaves like a real (albeit minimal) Linux server.</li> <li>Compatibility: Firecracker runs a real Linux kernel. gVisor emulates it. If your app relies on obscure kernel features, it's more likely to work in Firecracker (provided the kernel has the modules).</li> </ul>"},{"location":"faq/#infrastructure","title":"Infrastructure","text":""},{"location":"faq/#can-i-run-this-on-aws-ec2-gcp-or-azure","title":"Can I run this on AWS EC2, GCP, or Azure?","text":"<p>Yes, but with requirements. Firecracker requires KVM (Kernel-based Virtual Machine). Since cloud instances are already VMs, you need Nested Virtualization.</p> <ul> <li>AWS: You typically need Bare Metal instances (e.g., <code>c5.metal</code>, <code>m5.metal</code>). Standard instances (like <code>t3.medium</code>) do not support nested KVM.</li> <li>GCP: You must explicitly enable nested virtualization when creating the VM image or instance.</li> <li>Azure: The Dv3 and Ev3 series generally support nested virtualization.</li> </ul>"},{"location":"faq/#can-i-run-without-kvm-for-testing","title":"Can I run without KVM for testing?","text":"<p>Technically yes, via QEMU emulation. It is possible to run Firecracker inside a QEMU VM using software emulation (TCG) on non-metal cloud instances. This allows you to test the setup, but performance will be extremely slow. This is strictly for development/CI and not suitable for running workloads.</p>"},{"location":"faq/#does-it-support-gpus","title":"Does it support GPUs?","text":"<p>Not yet. Firecracker's design philosophy prioritizes security and minimalism, so PCI passthrough support is limited compared to QEMU. We are monitoring upstream Firecracker features for GPU support possibilities.</p>"},{"location":"faq/#do-you-support-arm64","title":"Do you support ARM64?","text":"<p>Planned. Firecracker supports ARM64, and our architecture supports it. We plan to add ARM64 build targets in the v0.2 roadmap.</p>"},{"location":"faq/#what-is-pvm-pagetable-based-virtual-machine","title":"What is PVM (Pagetable-based Virtual Machine)?","text":"<p>PVM is an emerging virtualization framework that allows running secure containers (like Firecracker) without hardware-assisted nested virtualization.</p> <ul> <li>Why it matters: Currently, running Firecracker inside a cloud VM requires Nested Virtualization. Many cloud providers disable this or only offer it on expensive Bare Metal instances.</li> <li>How it works: PVM decouples the secure container from hardware virtualization requirements by using a modified host kernel and a Position-Independent Executable (PIE) guest kernel.</li> <li>Status in firecracker-shim: Researching. Implementing PVM would enable our shim to run on any standard cloud instance, significantly reducing infrastructure costs.</li> </ul>"},{"location":"faq/#requirements-for-pvm","title":"Requirements for PVM","text":"<ul> <li>Patched Host Kernel: The host must run a Linux kernel with the PVM RFC patchset (introducing the <code>kvm-pvm</code> vendor module).</li> <li>PIE Guest Kernel: The guest OS must use a Position-Independent Executable (PIE) kernel that supports running in hardware Ring 3.</li> <li>x86_64 Architecture: Current PVM research is specific to x86_64 and requires Shadow Paging.</li> </ul>"},{"location":"faq/#known-limitations","title":"Known Limitations","text":"<ul> <li>Performance Overhead: PVM relies on Shadow Paging, which can lead to performance degradation in workloads that frequently modify page tables (e.g., high process fork rates). Long-running services like Java apps typically perform well.</li> <li>Feature Gaps: Direct SMAP/SMEP is not supported (requires emulation via PKU/NX). LDT and full PMU virtualization are currently not implemented in the initial PVM specifications.</li> <li>Instruction Emulation: Certain privileged instructions must be emulated in software since the guest runs in hardware Ring 3.</li> </ul>"},{"location":"faq/#operations","title":"Operations","text":""},{"location":"faq/#why-is-my-pod-stuck-in-containercreating","title":"Why is my pod stuck in <code>ContainerCreating</code>?","text":"<p>This usually means the shim failed to initialize the VM.</p> <ol> <li>Check KVM: Ensure <code>/dev/kvm</code> exists and is writable by the container runtime user (usually root).</li> <li>Check Logs: Run <code>sudo fcctl logs &lt;sandbox-id&gt;</code>.</li> <li>Check Config: Ensure <code>/var/lib/fc-cri/vmlinux</code> and <code>/var/lib/fc-cri/rootfs/base.ext4</code> exist.</li> </ol>"},{"location":"faq/#can-i-use-my-own-linux-kernel","title":"Can I use my own Linux Kernel?","text":"<p>Yes. The default kernel is minimal (~5MB) for speed. If you need specific modules (e.g., for specific networking protocols or filesystems like XFS), you can provide your own kernel. See Using a Custom Kernel in the Operations Guide.</p>"},{"location":"faq/#how-do-updates-work","title":"How do updates work?","text":"<p>The shim is stateless.</p> <ol> <li>Update the binaries on the host (or update the DaemonSet).</li> <li>Restart <code>containerd</code>.</li> <li>Existing pods continue running with the old shim process.</li> <li>New pods will use the updated shim.     To fully upgrade, you must drain the node or delete/recreate the pods.</li> </ol>"},{"location":"image-handling/","title":"Image Handling","text":"<p>One of the key differentiators of <code>firecracker-shim</code> is how it handles container images. Instead of requiring complex setups like Device Mapper (devmapper) or overlayfs inside the guest, we convert standard OCI (Docker) images into simple ext4 block devices on the host.</p> <p>This approach simplifies operations but comes with specific trade-offs.</p>"},{"location":"image-handling/#how-it-works","title":"How It Works","text":"<ol> <li>Pull: When a pod is scheduled, <code>containerd</code> pulls the image layers to the host as usual.</li> <li>Convert: The shim (via <code>fsify</code>) takes these layers and merges them into a single directory structure.</li> <li>Build: It creates a sparse <code>.ext4</code> filesystem file and copies the merged content into it.</li> <li>Attach: This file is attached to the Firecracker microVM as a read-only block device (<code>/dev/vdb</code>).</li> <li>Mount: The in-guest agent mounts this device as the container's root filesystem.</li> </ol>"},{"location":"image-handling/#caching-strategy","title":"Caching Strategy","text":"<p>Conversion takes time (seconds for large images). To mitigate this, we implement a Host-Side Conversion Cache.</p> <ul> <li>Cache Location: <code>/var/lib/fc-cri/images/cache/</code></li> <li>Key: Image Digest (SHA256)</li> <li>Behavior:<ul> <li>First run: Pull -&gt; Convert -&gt; Cache -&gt; Run (~seconds)</li> <li>Subsequent runs: Cache Hit -&gt; Run (&lt;100ms)</li> </ul> </li> </ul> <p>The cache is shared across all pods on the node.</p>"},{"location":"image-handling/#supported-features","title":"Supported Features","text":"Feature Status Notes Standard Images Supported Debian, Alpine, Ubuntu, Distroless work out of the box. Large Images Supported Tested up to 10GB. Conversion time scales with size. Whiteouts (.wh) Supported Correctly handles file deletion in upper layers. Symlinks Supported Preserves standard symlink behavior. User/Group Ownership Supported Preserves UID/GID from the image. File Capabilities Supported <code>setcap</code> bits are preserved in the ext4 image."},{"location":"image-handling/#limitations-constraints","title":"Limitations &amp; Constraints","text":""},{"location":"image-handling/#1-startup-latency-cold","title":"1. Startup Latency (Cold)","text":"<p>The first time an image is used on a node, there is a conversion penalty. *   Alpine (5MB): &lt; 100ms *   Ubuntu (30MB): ~500ms *   Heavy App (1GB): ~2-5 seconds</p> <p>Mitigation: Pre-pull images or use the VM pool (which doesn't solve image conversion but speeds up VM boot).</p>"},{"location":"image-handling/#2-disk-usage","title":"2. Disk Usage","text":"<p>We create a full flattened copy of the image. While we use sparse files (only allocating used blocks), this consumes more disk space than overlayfs which shares layers between images. *   Mitigation: Run a periodic cleanup script to prune <code>/var/lib/fc-cri/images/cache/</code>.</p>"},{"location":"image-handling/#3-read-only-rootfs","title":"3. Read-Only Rootfs","text":"<p>By default, the container's root filesystem is mounted Read-Only for security. *   Writes: Use <code>emptyDir</code> volumes or standard Kubernetes volumes for writable paths. *   Overlay: We do not currently overlay a writable tmpfs on top of the rootfs inside the guest (to keep the agent simple). This enforces immutable infrastructure patterns.</p>"},{"location":"image-handling/#security-guarantees","title":"Security Guarantees","text":"<ul> <li>Host Processing: Image parsing and conversion happen on the host. Malicious filesystem structures are processed by the host kernel/tools.</li> <li>Isolation: The resulting ext4 image is exposed to the guest as a block device. The guest kernel parses the ext4 filesystem.</li> <li>Integrity: We verify image digests before conversion (relies on containerd).</li> </ul>"},{"location":"image-handling/#troubleshooting","title":"Troubleshooting","text":"<p>Symptoms: \"Image unpack failed\" or \"No space left on device\".</p> <p>Checks: 1.  Disk Space: Ensure <code>/var/lib/fc-cri</code> has sufficient space. 2.  Permissions: Ensure the shim has write access to the cache dir. 3.  Logs: Check shim logs for <code>fsify</code> errors.</p> <pre><code># Clear the cache manually if corrupted\nsudo rm -rf /var/lib/fc-cri/images/cache/*\n</code></pre>"},{"location":"installation/","title":"Installation Guide","text":"<p>This guide covers the installation of <code>firecracker-shim</code> in various environments.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing, ensure your environment meets the following requirements:</p>"},{"location":"installation/#hardware-vm","title":"Hardware / VM","text":"<ul> <li>Architecture: x86_64 (AMD64)</li> <li>Virtualization: KVM support is required.</li> <li>Bare Metal: Enable VT-x/AMD-V in BIOS.</li> <li>Cloud (AWS): Use <code>.metal</code> instances (e.g., <code>c5.metal</code>) OR instances with nested virtualization enabled.</li> <li>Local (Linux): Verify with <code>kvm-ok</code> or check <code>ls -la /dev/kvm</code>.</li> </ul>"},{"location":"installation/#software","title":"Software","text":"<ul> <li>OS: Linux (Kernel 4.14+, recommended 5.10+)</li> <li>Container Runtime: <code>containerd</code> 1.7+</li> <li>Kubernetes: 1.24+ (if using with K8s)</li> </ul>"},{"location":"installation/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/#method-1-kubernetes-daemonset-recommended","title":"Method 1: Kubernetes DaemonSet (Recommended)","text":"<p>The easiest way to install on a Kubernetes cluster. This deploys a privileged pod to every node that installs the necessary binaries and configuration.</p> <ol> <li> <p>Deploy the Installer:</p> <pre><code>kubectl apply -f https://github.com/PipeOpsHQ/firecracker-shim/releases/latest/download/firecracker-shim-installer.yaml\n</code></pre> </li> <li> <p>Verify Installation:     Check the logs of the installer pods:</p> <pre><code>kubectl -n kube-system logs -l app=firecracker-shim-installer\n</code></pre> <p>You should see \"Installation successful!\".</p> </li> <li> <p>Install RuntimeClass:     Apply the RuntimeClass definition to allow pods to request this runtime.     <pre><code>apiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: firecracker\nhandler: firecracker\noverhead:\n  podFixed:\n    memory: \"64Mi\"\n    cpu: \"100m\"\nscheduling:\n  nodeSelector:\n    fc-cri.io/enabled: \"true\"\n</code></pre>     Save as <code>runtime-class.yaml</code> and apply:     <pre><code>kubectl apply -f runtime-class.yaml\n</code></pre></p> </li> </ol>"},{"location":"installation/#method-2-manual-installation-linux-host","title":"Method 2: Manual Installation (Linux Host)","text":"<p>For development or single-node setups without Kubernetes.</p> <ol> <li> <p>Download Release:     Get the latest release from GitHub Releases.</p> <pre><code>VERSION=\"v0.1.0\"\nwget https://github.com/PipeOpsHQ/firecracker-shim/releases/download/${VERSION}/firecracker-shim_${VERSION}_linux_amd64.tar.gz\ntar xf firecracker-shim_${VERSION}_linux_amd64.tar.gz\n</code></pre> </li> <li> <p>Install Binaries:</p> <pre><code>sudo cp containerd-shim-fc-v2 /usr/local/bin/\nsudo cp fc-agent /usr/local/bin/\nsudo cp fcctl /usr/local/bin/\n</code></pre> </li> <li> <p>Install Assets (Kernel &amp; Rootfs):     You need a compatible Linux kernel and a base rootfs for the VM.</p> <p>Development/Test Assets:</p> <pre><code>sudo mkdir -p /var/lib/fc-cri/rootfs\n\n# Download test assets (example URLs - replace with your build or trusted source)\n# wget -O /var/lib/fc-cri/vmlinux https://s3.amazonaws.com/spec.ccfc.min/img/quickstart_guide/x86_64/kernels/vmlinux-5.10.186\n# wget -O /var/lib/fc-cri/rootfs/base.ext4 https://...\n</code></pre> <p>Alternatively, build them using <code>make kernel</code> and <code>make rootfs</code> in the repo.</p> </li> <li> <p>Install Config:</p> <pre><code>sudo mkdir -p /etc/fc-cri\nsudo cp config.toml /etc/fc-cri/\n</code></pre> </li> <li> <p>Configure containerd:     Add the runtime plugin to <code>/etc/containerd/config.toml</code>:     <pre><code>[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.firecracker]\n  runtime_type = \"io.containerd.firecracker.v2\"\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.firecracker.options]\n    ConfigPath = \"/etc/fc-cri/config.toml\"\n</code></pre>     Restart containerd:     <pre><code>sudo systemctl restart containerd\n</code></pre></p> </li> </ol>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":""},{"location":"installation/#1-check-component-health","title":"1. Check Component Health","text":"<p>Use the <code>fcctl</code> tool to verify the runtime components.</p> <pre><code>sudo fcctl health\n</code></pre> <p>Expected output:</p> <pre><code>[OK] Runtime is healthy\nComponents:\n  [OK]  runtime_dir          ok\n  [OK]  kvm                  ok\n  [OK]  firecracker          ok\n  [OK]  kernel               ok\n  [OK]  rootfs               ok\n</code></pre>"},{"location":"installation/#2-run-a-test-pod","title":"2. Run a Test Pod","text":"<p>Create a pod using the <code>firecracker</code> runtime class.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-fc\nspec:\n  runtimeClassName: firecracker\n  containers:\n    - name: nginx\n      image: nginx:alpine\n</code></pre> <pre><code>kubectl apply -f pod.yaml\nkubectl get pod test-fc -o wide\n</code></pre> <p>If the pod reaches <code>Running</code> state, congratulations! You are running a container inside a Firecracker microVM.</p>"},{"location":"installation/#3-inspect-the-vm","title":"3. Inspect the VM","text":"<p>On the worker node where the pod is running:</p> <pre><code>sudo fcctl list\nsudo fcctl inspect &lt;sandbox-id&gt;\n</code></pre>"},{"location":"installation/#uninstalling","title":"Uninstalling","text":""},{"location":"installation/#daemonset-uninstall","title":"DaemonSet Uninstall","text":"<pre><code>kubectl delete -f https://github.com/PipeOpsHQ/firecracker-shim/releases/latest/download/firecracker-shim-installer.yaml\n</code></pre> <p>Note: This removes the installer, but binaries may persist on nodes depending on cleanup policy. To fully clean nodes, you may need to run a cleanup script.</p>"},{"location":"installation/#manual-uninstall","title":"Manual Uninstall","text":"<pre><code># Remove config\nsudo rm /etc/containerd/config.d/firecracker.toml\nsudo systemctl restart containerd\n\n# Remove binaries\nsudo rm /usr/local/bin/containerd-shim-fc-v2\nsudo rm /usr/local/bin/fc-agent\nsudo rm /usr/local/bin/fcctl\n\n# Remove assets\nsudo rm -rf /var/lib/fc-cri\nsudo rm -rf /etc/fc-cri\n</code></pre>"},{"location":"launch-post/","title":"Introducing firecracker-shim: Firecracker for Kubernetes, Simplified","text":"<p>Today we're releasing firecracker-shim (fc-cri), a lightweight container runtime that brings Firecracker microVM isolation to Kubernetes without the complexity of existing solutions.</p>"},{"location":"launch-post/#why-another-runtime","title":"Why Another Runtime?","text":"<p>If you want stronger isolation than standard Linux containers (cgroups/namespaces), you typically look at two options: Kata Containers or firecracker-containerd. Both are excellent, but we found them operationally complex for our needs.</p>"},{"location":"launch-post/#vs-firecracker-containerd","title":"vs. firecracker-containerd","text":"<p>AWS's <code>firecracker-containerd</code> pioneered this space, but it uses a daemon-based architecture that sits between containerd and the VMs. This adds complexity to debugging, image handling (often requiring custom snapshotters), and networking setup.</p> <p>firecracker-shim takes a different approach:</p> <ul> <li>Shim v2 Architecture: No middleman daemon. containerd talks directly to our shim, which talks directly to Firecracker.</li> <li>Standard OCI Images: No complex device mapper setup. We convert standard Docker images to ext4 block devices on the fly.</li> <li>Standard Networking: We use standard CNI plugins via a bridge, so your existing Calico/Flannel/AWS-VPC-CNI just works.</li> </ul>"},{"location":"launch-post/#vs-kata-containers","title":"vs. Kata Containers","text":"<p>Kata is a powerful, multi-hypervisor runtime (QEMU, Cloud Hypervisor, etc.). That flexibility comes with abstraction overhead (~160MB+ memory per pod vs our ~64MB) and a larger architectural footprint.</p> <p>We built firecracker-shim to be:</p> <ol> <li>Single-purpose: Optimized solely for Firecracker.</li> <li>Lean: Minimal agent (~2MB), minimal kernel, minimal overhead.</li> <li>Fast: Sub-50ms warm starts via VM pooling.</li> </ol>"},{"location":"launch-post/#architecture","title":"Architecture","text":"<p>firecracker-shim is a purpose-built containerd shim (v2) that maps Kubernetes Pods 1:1 to Firecracker microVMs.</p> <pre><code>Kubernetes \u2192 kubelet \u2192 containerd \u2192 firecracker-shim \u2192 Firecracker VM\n                                                            \u2193\n                                                       fc-agent \u2192 runc \u2192 container\n</code></pre> <p>It\u2019s designed with a \"less is more\" philosophy:</p> <ul> <li>No proxy sidecars: Direct communication via vsock.</li> <li>No complex agents: A minimal 2MB static agent inside the VM.</li> <li>No multi-hypervisor abstraction: Optimized solely for Firecracker.</li> </ul>"},{"location":"launch-post/#key-features","title":"Key Features","text":""},{"location":"launch-post/#speed-efficiency","title":"Speed &amp; Efficiency","text":"<ul> <li>&lt;150ms Cold Starts: From pod creation to running container.</li> <li>&lt;50ms Warm Starts: Pre-warmed VM pool for instant provisioning.</li> <li>64MB Overhead: Run thousands of secure pods on a single node.</li> </ul>"},{"location":"launch-post/#real-isolation","title":"Real Isolation","text":"<p>Each pod gets its own kernel. If a container breaks out, it\u2019s trapped in the microVM, protecting the host and other tenants.</p>"},{"location":"launch-post/#kubernetes-native","title":"Kubernetes Native","text":"<p>It works out of the box with standard Kubernetes networking (CNI) and storage. Use it with a simple RuntimeClass:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: secure-workload\nspec:\n  runtimeClassName: firecracker\n  containers:\n    - name: app\n      image: nginx:alpine\n</code></pre>"},{"location":"launch-post/#how-it-works","title":"How It Works","text":"<ol> <li>VM Pooling: We maintain a pool of \"paused\" microVMs booted with a minimal kernel and agent.</li> <li>Hot Plug: When a pod is scheduled, we grab a VM and hot-attach the container's root filesystem (converted from the OCI image).</li> <li>CNI Bridge: We wire the VM's tap device to the CNI network, making the pod indistinguishable from a regular container on the network.</li> </ol>"},{"location":"launch-post/#getting-started","title":"Getting Started","text":"<p>You can try it today on any Linux machine with KVM support.</p> <ol> <li>Install:</li> </ol> <pre><code>git clone https://github.com/PipeOpsHQ/firecracker-shim\nmake install\n</code></pre> <ol> <li>Configure Kubernetes:</li> </ol> <pre><code>kubectl apply -f deploy/kubernetes/runtime-class.yaml\n</code></pre> <ol> <li>Run:    <pre><code>kubectl apply -f deploy/kubernetes/example-pod.yaml\n</code></pre></li> </ol>"},{"location":"launch-post/#whats-next","title":"What's Next?","text":"<p>This is an initial release (v0.1) but it's already feature-rich. We've implemented:</p> <ul> <li>Snapshot Support: Sub-10ms restore times for lightning-fast scaling.</li> <li>Production Hardening: Full jailer integration with chroot and cgroups isolation.</li> </ul> <p>Our roadmap for v0.2 includes:</p> <ul> <li>Multi-arch Support: ARM64 builds for running on Graviton/Ampere.</li> <li>Conformance: Passing 100% of the Kubernetes e2e suite.</li> </ul> <p>Check out the code on GitHub and let us know what you think!</p>"},{"location":"operations/","title":"firecracker-shim Operations Guide","text":"<p>This guide covers the deployment, configuration, troubleshooting, and maintenance of the <code>firecracker-shim</code> runtime in production environments.</p>"},{"location":"operations/#architecture-overview","title":"Architecture Overview","text":"<p>The runtime operates as a containerd shim (<code>io.containerd.firecracker.v2</code>). When Kubernetes creates a pod, the following happens:</p> <ol> <li>kubelet calls containerd (via CRI) to create a PodSandbox.</li> <li>containerd spawns a new instance of containerd-shim-fc-v2.</li> <li>The shim acquires a Firecracker microVM (from pool or new).</li> <li>Inside the VM, fc-agent starts and listens on vsock.</li> <li>Container operations (create, start, exec) are proxied to the agent.</li> </ol>"},{"location":"operations/#deployment-requirements","title":"Deployment Requirements","text":""},{"location":"operations/#host-requirements","title":"Host Requirements","text":"<ul> <li>OS: Linux (kernel 4.14+)</li> <li>Virtualization: KVM enabled (<code>/dev/kvm</code> accessible)</li> <li>vsock: <code>vhost_vsock</code> kernel module loaded</li> <li>containerd: Version 1.7+</li> <li>CNI Plugins: Standard plugins installed (<code>bridge</code>, <code>ptp</code>, <code>host-local</code>, etc.)</li> </ul>"},{"location":"operations/#sizing-recommendations","title":"Sizing Recommendations","text":"Component CPU Memory Disk Shim process &lt; 1% core ~10MB Negligible Firecracker VMM &lt; 1% core (idle) ~5MB Negligible Guest VM 1+ vCPU 64MB+ (configurable) Rootfs size <p>Recommended Host Config:</p> <ul> <li>Enable hugepages for better VM memory performance (optional)</li> <li>Use <code>mq-deadline</code> or <code>none</code> I/O scheduler for backing files</li> </ul>"},{"location":"operations/#configuration","title":"Configuration","text":"<p>Configuration is loaded from <code>/etc/fc-cri/config.toml</code>.</p>"},{"location":"operations/#vm-sizing","title":"VM Sizing","text":"<p>Adjust based on your workload needs:</p> <pre><code>[vm]\n# Default vCPUs per VM\nvcpu_count = 2\n\n# Default memory per VM in MB\nmemory_mb = 256\n\n# Minimum memory (if requested via pod resources)\nmin_memory_mb = 64\n\n# Maximum memory cap\nmax_memory_mb = 4096\n</code></pre>"},{"location":"operations/#vm-pool-tuning","title":"VM Pool Tuning","text":"<p>The pool significantly reduces cold start latency. Tuning depends on your pod churn rate.</p> <pre><code>[pool]\nenabled = true\n\n# Max VMs to keep warm (memory cost: ~size * memory_mb)\nmax_size = 20\n\n# Min VMs to always have ready\nmin_size = 5\n\n# Concurrency for warming (limit to avoid CPU spikes)\nwarm_concurrency = 4\n</code></pre>"},{"location":"operations/#networking","title":"Networking","text":"<p>The runtime supports standard CNI. The default setup uses a bridge.</p> <p>Important: Ensure the subnet doesn't overlap with your host or pod network.</p> <pre><code>[network]\n# Default subnet if not using CNI config\ndefault_subnet = \"10.88.0.0/16\"\n</code></pre>"},{"location":"operations/#security-jailer","title":"Security (Jailer)","text":"<p>For production, always enable the jailer.</p> <pre><code>[runtime]\nenable_jailer = true\njailer_binary = \"/usr/bin/jailer\"\n\n# UID/GID to run Firecracker as (must exist)\nuid = 1000\ngid = 1000\n</code></pre> <p>Prerequisites for Jailer:</p> <ul> <li>User <code>1000:1000</code> exists</li> <li><code>/srv/jailer</code> directory exists and is owned by <code>root:root</code></li> <li>Cgroup v2 is recommended</li> </ul>"},{"location":"operations/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/#tools","title":"Tools","text":"<p>The <code>fcctl</code> CLI is your primary troubleshooting tool.</p> <pre><code># Check runtime health\nsudo fcctl health\n\n# List all sandboxes\nsudo fcctl list\n\n# Inspect specific sandbox\nsudo fcctl inspect &lt;sandbox-id&gt;\n</code></pre>"},{"location":"operations/#common-issues","title":"Common Issues","text":""},{"location":"operations/#1-pods-stuck-in-containercreating","title":"1. Pods stuck in <code>ContainerCreating</code>","text":"<p>Symptoms: Pod status stays in <code>ContainerCreating</code> for &gt;30s.</p> <p>Checks:</p> <ol> <li>Check runtime health: <code>fcctl health</code></li> <li>Check shim logs: <code>journalctl -u containerd</code> or <code>/var/lib/containerd/io.containerd.runtime.v2.task/.../log</code></li> <li>Verify VM started: <code>fcctl list</code></li> <li>Check agent connection: <code>fcctl inspect &lt;id&gt;</code></li> </ol> <p>Possible Causes:</p> <ul> <li>KVM missing: Ensure <code>/dev/kvm</code> exists and is accessible.</li> <li>Kernel/Rootfs missing: Verify <code>/var/lib/fc-cri/vmlinux</code> exists.</li> <li>vsock failure: Ensure <code>vhost_vsock</code> module is loaded.</li> </ul>"},{"location":"operations/#2-network-connectivity-issues","title":"2. Network Connectivity Issues","text":"<p>Symptoms: Container cannot reach external network or other pods.</p> <p>Checks:</p> <ol> <li>Check CNI bridge: <code>ip addr show fc-br0</code></li> <li>Check VM IP: <code>fcctl inspect &lt;id&gt;</code></li> <li>Test from inside: <code>fcctl exec &lt;id&gt; ping 8.8.8.8</code></li> </ol> <p>Possible Causes:</p> <ul> <li>IP exhaustion: Check CNI subnet size vs number of pods.</li> <li>Firewall: Ensure <code>iptables</code> allows forwarding on <code>fc-br0</code>.</li> </ul>"},{"location":"operations/#3-high-host-memory-usage","title":"3. High Host Memory Usage","text":"<p>Symptoms: Host OOM killer active.</p> <p>Checks:</p> <ol> <li>Check pool size: <code>fcctl pool status</code></li> <li>Check active VMs: <code>fcctl list | wc -l</code></li> </ol> <p>Mitigation:</p> <ul> <li>Reduce pool size.</li> <li>Reduce default VM memory in <code>config.toml</code>.</li> <li>Enable memory overcommitment (ensure swap is available).</li> </ul>"},{"location":"operations/#monitoring","title":"Monitoring","text":""},{"location":"operations/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>The runtime exposes metrics at <code>:9090/metrics</code>.</p> <p>Key Metrics to Alert On:</p> Metric Condition Severity Description <code>fc_cri_vm_create_errors_total</code> rate &gt; 0 High VM creation failing <code>fc_cri_agent_connect_errors_total</code> rate &gt; 0 High Agent unreachable <code>fc_cri_pool_available</code> == 0 Warning Pool exhausted (latency impact) <code>fc_cri_start_latency_p95_ms</code> &gt; 500ms Warning Slow startup"},{"location":"operations/#logging","title":"Logging","text":"<p>Logs are written to stdout (captured by containerd) or a file.</p> <p>Log Levels:</p> <ul> <li><code>info</code>: Normal operations (VM start/stop)</li> <li><code>warn</code>: Retryable errors, resource pressure</li> <li><code>error</code>: Operational failures requiring attention</li> <li><code>debug</code>: Detailed trace (verbose!)</li> </ul> <p>Change level via environment variable for specific pods:</p> <pre><code>env:\n  - name: FC_CRI_LOG_LEVEL\n    value: \"debug\"\n</code></pre>"},{"location":"operations/#upgrades","title":"Upgrades","text":"<ol> <li>Drain node: <code>kubectl drain &lt;node&gt; --ignore-daemonsets</code></li> <li>Stop containerd: <code>systemctl stop containerd</code></li> <li>Install new binaries: <code>make install</code></li> <li>Update config: Check <code>config.toml</code> for new options.</li> <li>Start containerd: <code>systemctl start containerd</code></li> <li>Uncordon node: <code>kubectl uncordon &lt;node&gt;</code></li> </ol> <p>Note: Upgrading the shim binary does not affect running VMs. Only new pods will use the new shim version.</p>"},{"location":"operations/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"operations/#cleaning-orphaned-resources","title":"Cleaning Orphaned Resources","text":"<p>If the shim crashes hard, it might leave VMs running or files on disk.</p> <pre><code># Dry run cleanup\nsudo fcctl cleanup --dry-run\n\n# Force cleanup\nsudo fcctl cleanup\n</code></pre>"},{"location":"operations/#recovering-from-bad-state","title":"recovering from Bad State","text":"<p>If the runtime is completely stuck:</p> <ol> <li>Stop containerd: <code>systemctl stop containerd</code></li> <li>Kill all Firecracker processes: <code>pkill firecracker</code></li> <li>Remove runtime state: <code>rm -rf /run/fc-cri/*</code></li> <li>Start containerd: <code>systemctl start containerd</code></li> </ol> <p>Warning: This will kill all running pods on the node.</p>"},{"location":"operations/#advanced-using-a-custom-kernel","title":"Advanced: Using a Custom Kernel","text":"<p>The default minimal kernel (~5MB) is optimized for speed and supports standard container workloads. However, it lacks support for advanced filesystems (XFS, ZFS), complex networking protocols (SCTP), or specific hardware drivers.</p> <p>If your workload fails due to missing kernel features, you can swap in a standard kernel.</p> <p>Steps:</p> <ol> <li>Obtain a Kernel: Compile your own or download an AWS Firecracker-compatible kernel (e.g., from the Firecracker CI artifacts or Amazon Linux 2 kernel).</li> <li>Place on Host: Copy the <code>vmlinux</code> file to <code>/var/lib/fc-cri/custom-vmlinux</code>.</li> <li>Update Config:     Edit <code>/etc/fc-cri/config.toml</code>:     <pre><code>[vm]\nkernel_path = \"/var/lib/fc-cri/custom-vmlinux\"\n# Ensure boot args match your kernel requirements\nkernel_args = \"console=ttyS0 reboot=k panic=1 pci=off quiet\"\n</code></pre></li> <li>Restart: New pods will use the new kernel immediately. Existing pods (and pooled VMs) must be recycled.     <pre><code># Clear the pool\nsudo systemctl restart containerd\n</code></pre></li> </ol>"},{"location":"security/","title":"Security &amp; Trust","text":"<p>Security is the primary driver for using Firecracker. This document outlines our threat model, security boundaries, and trust mechanisms.</p>"},{"location":"security/#threat-model","title":"Threat Model","text":""},{"location":"security/#the-goal","title":"The Goal","text":"<p>The primary security goal of <code>firecracker-shim</code> is to protect the host infrastructure (and by extension, other tenants) from untrusted or malicious workloads running inside Kubernetes pods.</p>"},{"location":"security/#security-boundaries","title":"Security Boundaries","text":"<ol> <li> <p>Hardware Virtualization (Strong)</p> <ul> <li>Boundary: The KVM hypervisor.</li> <li>Protection: Prevents code running in the guest (kernel or user space) from accessing host memory or executing code on the host. This is the strongest layer of defense.</li> </ul> </li> <li> <p>Jailer (Defense-in-Depth)</p> <ul> <li>Boundary: Chroot, Cgroups, Seccomp on the host.</li> <li>Protection: Even if a process escapes the KVM boundary (e.g., via a QEMU/Firecracker vulnerability), the Firecracker process itself is trapped in a restrictive chroot, has dropped capabilities, and is limited by seccomp filters.</li> </ul> </li> <li> <p>Pod Boundary</p> <ul> <li>Scope: 1 MicroVM = 1 Pod.</li> <li>Protection: Containers within the same pod share the guest kernel and network namespace. They are not isolated from each other via virtualization. Malicious code in one container can potentially compromise others in the same pod, but cannot breach the VM to reach the host.</li> </ul> </li> </ol>"},{"location":"security/#what-we-do-not-protect-against","title":"What We Do Not Protect Against","text":"<ul> <li>Side-Channel Attacks: While Firecracker mitigates many speculative execution attacks (Spectre/Meltdown), complete immunity depends on host hardware and kernel patches.</li> <li>Intra-Pod Attacks: We do not provide hard isolation between sidecars and app containers in the same pod.</li> </ul>"},{"location":"security/#secure-defaults","title":"Secure Defaults","text":"<p>We ship with \"secure by default\" configurations:</p> <ul> <li>Jailer Enabled: The shim expects to run Firecracker via the <code>jailer</code> binary.</li> <li>Seccomp Filters: We apply Firecracker's strict seccomp filters to the VMM process.</li> <li>Dropped Privileges: The VMM runs as a non-root user (<code>uid: 1000</code>) inside the jail.</li> <li>Network Isolation: VMs are connected via TAP devices; they cannot sniff traffic from other VMs on the bridge unless specifically configured (promiscuous mode is off).</li> </ul>"},{"location":"security/#artifact-provenance-trust","title":"Artifact Provenance &amp; Trust","text":"<p>When you install <code>firecracker-shim</code>, you are running binary code on your cluster. Here is how we build trust:</p>"},{"location":"security/#1-binaries","title":"1. Binaries","text":"<ul> <li>Source: Built from this repository using GitHub Actions.</li> <li>Reproducibility: Builds are run in standard runners. We aim for reproducible builds (future roadmap).</li> <li>Checksums: Every release includes a <code>checksums.txt</code> containing SHA256 hashes of all artifacts.</li> </ul>"},{"location":"security/#2-installer-image","title":"2. Installer Image","text":"<ul> <li>Source: <code>ghcr.io/pipeopshq/firecracker-shim-installer</code></li> <li>Contents:<ul> <li><code>firecracker-shim</code> binaries (built by us).</li> <li><code>firecracker</code> and <code>jailer</code> binaries (downloaded directly from AWS Firecracker releases).</li> <li><code>vmlinux</code> kernel (built by us or sourced from AWS examples).</li> <li><code>base.ext4</code> rootfs (built via <code>scripts/create-rootfs.sh</code> using Alpine Linux).</li> </ul> </li> </ul>"},{"location":"security/#3-release-signing","title":"3. Release Signing","text":"<ul> <li>We publish SHA256 checksums for all release artifacts.</li> <li>Future: We plan to sign releases using Cosign / Sigstore for verifiable supply chain security.</li> </ul>"},{"location":"security/#daemonset-installer-security","title":"DaemonSet Installer Security","text":"<p>The installer runs as a Privileged Pod because it must: 1.  Write executable binaries to the host (<code>/usr/local/bin</code>). 2.  Restart the system service (<code>containerd</code>).</p> <p>Risk Mitigation: *   Transparency: The installer script is simple bash (<code>deploy/installer/install.sh</code>). You can audit it. *   Minimal Base: We use <code>alpine</code> as the base image. *   Least Privilege (Planned): We are exploring ways to reduce privileges, but host modification inherently requires root access.</p>"},{"location":"security/#reporting-vulnerabilities","title":"Reporting Vulnerabilities","text":"<p>If you find a security issue, please DO NOT open a public issue. Email security@pipeops.io with details. We will respond within 48 hours.</p>"}]}